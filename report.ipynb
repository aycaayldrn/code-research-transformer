{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952254a-86a4-4550-ad7b-206fa57cb3fb",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11c7515-858e-4f44-a431-38ee36b923c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\aycay\\anaconda3\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: usearch in c:\\users\\aycay\\anaconda3\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aycay\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\aycay\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aycay\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "WARNING:tensorflow:From C:\\Users\\aycay\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[[ 6.76568821e-02  6.34959936e-02  4.87131141e-02  7.93049484e-02\n",
      "   3.74481082e-02  2.65281019e-03  3.93750109e-02 -7.09848432e-03\n",
      "   5.93614094e-02  3.15369926e-02  6.00981005e-02 -5.29051758e-02\n",
      "   4.06067446e-02 -2.59308759e-02  2.98428461e-02  1.12691789e-03\n",
      "   7.35148489e-02 -5.03818877e-02 -1.22386619e-01  2.37028655e-02\n",
      "   2.97265742e-02  4.24768887e-02  2.56337579e-02  1.99517026e-03\n",
      "  -5.69190569e-02 -2.71598063e-02 -3.29035297e-02  6.60248920e-02\n",
      "   1.19007193e-01 -4.58791070e-02 -7.26214647e-02 -3.25840414e-02\n",
      "   5.23413345e-02  4.50553559e-02  8.25301651e-03  3.67024057e-02\n",
      "  -1.39415748e-02  6.53918460e-02 -2.64272299e-02  2.06413330e-04\n",
      "  -1.36643304e-02 -3.62810455e-02 -1.95044074e-02 -2.89737955e-02\n",
      "   3.94270308e-02 -8.84090438e-02  2.62422604e-03  1.36713414e-02\n",
      "   4.83062416e-02 -3.11566312e-02 -1.17329173e-01 -5.11690117e-02\n",
      "  -8.85287970e-02 -2.18962729e-02  1.42986486e-02  4.44168076e-02\n",
      "  -1.34815639e-02  7.43392110e-02  2.66382620e-02 -1.98762491e-02\n",
      "   1.79191492e-02 -1.06052151e-02 -9.04262662e-02  2.13269107e-02\n",
      "   1.41204849e-01 -6.47175917e-03 -1.40378042e-03 -1.53609486e-02\n",
      "  -8.73572007e-02  7.22173974e-02  2.01403052e-02  4.25587408e-02\n",
      "  -3.49013917e-02  3.19448038e-04 -8.02970976e-02 -3.27472463e-02\n",
      "   2.85268389e-02 -5.13657816e-02  1.09389178e-01  8.19327757e-02\n",
      "  -9.84039977e-02 -9.34096277e-02 -1.51292030e-02  4.51248810e-02\n",
      "   4.94172275e-02 -2.51867995e-02  1.57077387e-02 -1.29290745e-01\n",
      "   5.31890383e-03  4.02342947e-03 -2.34571677e-02 -6.72982857e-02\n",
      "   2.92280074e-02 -2.60845125e-02  1.30625013e-02 -3.11662629e-02\n",
      "  -4.82713655e-02 -5.58859408e-02 -3.87504995e-02  1.20010853e-01\n",
      "  -1.03924377e-02  4.89705168e-02  5.53536639e-02  4.49358113e-02\n",
      "  -4.00978327e-03 -1.02959730e-01 -2.92968545e-02 -5.83403036e-02\n",
      "   2.70472560e-02 -2.20169015e-02 -7.22241327e-02 -4.13870029e-02\n",
      "  -1.93298012e-02  2.73332489e-03  2.77016632e-04 -9.67588648e-02\n",
      "  -1.00574695e-01 -1.41922841e-02 -8.07892084e-02  4.53925095e-02\n",
      "   2.45041288e-02  5.97613640e-02 -7.38184899e-02  1.19844452e-02\n",
      "  -6.63403496e-02 -7.69045055e-02  3.85158211e-02 -5.59362366e-33\n",
      "   2.80013904e-02 -5.60785271e-02 -4.86601666e-02  2.15569008e-02\n",
      "   6.01980723e-02 -4.81403023e-02 -3.50247100e-02  1.93314273e-02\n",
      "  -1.75152291e-02 -3.89210135e-02 -3.81062622e-03 -1.70287788e-02\n",
      "   2.82099750e-02  1.28291156e-02  4.71600965e-02  6.21030554e-02\n",
      "  -6.43588752e-02  1.29285619e-01 -1.31231025e-02  5.23069389e-02\n",
      "  -3.73680703e-02  2.89094970e-02 -1.68980919e-02 -2.37330627e-02\n",
      "  -3.33491936e-02 -5.16762845e-02  1.55356694e-02  2.08802707e-02\n",
      "  -1.25372149e-02  4.59578969e-02  3.72719541e-02  2.80566774e-02\n",
      "  -5.90004921e-02 -1.16988290e-02  4.92183045e-02  4.70329411e-02\n",
      "   7.35487640e-02 -3.70529965e-02  3.98456864e-03  1.06411986e-02\n",
      "  -1.61471209e-04 -5.27165793e-02  2.75928080e-02 -3.92921083e-02\n",
      "   8.44717696e-02  4.86860797e-02 -4.85871779e-03  1.79948956e-02\n",
      "  -4.28569689e-02  1.23375403e-02  6.39953325e-03  4.04823311e-02\n",
      "   1.48887131e-02 -1.53941521e-02  7.62948766e-02  2.37044264e-02\n",
      "   4.45237085e-02  5.08196279e-02 -2.31253728e-03 -1.88736729e-02\n",
      "  -1.23335607e-02  4.66001555e-02 -5.63437752e-02  6.29927889e-02\n",
      "  -3.15535069e-02  3.24912220e-02  2.34673340e-02 -6.55438229e-02\n",
      "   2.01709308e-02  2.57082582e-02 -1.23869274e-02 -8.36488232e-03\n",
      "  -6.64377734e-02  9.43073556e-02 -3.57092731e-02 -3.42483371e-02\n",
      "  -6.66355714e-03 -8.01528059e-03 -3.09711266e-02  4.33012545e-02\n",
      "  -8.21398851e-03 -1.50795043e-01  3.07692029e-02  4.00719009e-02\n",
      "  -3.79293375e-02  1.93215604e-03  4.00530919e-02 -8.77075195e-02\n",
      "  -3.68490405e-02  8.57959595e-03 -3.19251716e-02 -1.25257522e-02\n",
      "   7.35539943e-02  1.34740269e-03  2.05918606e-02  2.71098293e-33\n",
      "  -5.18577173e-02  5.78361154e-02 -9.18985456e-02  3.94421294e-02\n",
      "   1.05576523e-01 -1.96911786e-02  6.18402474e-02 -7.63465092e-02\n",
      "   2.40880437e-02  9.40048918e-02 -1.16535425e-01  3.71198319e-02\n",
      "   5.22425100e-02 -3.95854842e-03  5.72214387e-02  5.32852579e-03\n",
      "   1.24016851e-01  1.39022227e-02 -1.10250302e-02  3.56053300e-02\n",
      "  -3.30754705e-02  8.16574320e-02 -1.52004054e-02  6.05585165e-02\n",
      "  -6.01397417e-02  3.26102450e-02 -3.48296650e-02 -1.69881433e-02\n",
      "  -9.74907354e-02 -2.71484647e-02  1.74713752e-03 -7.68982247e-02\n",
      "  -4.31858040e-02 -1.89984534e-02 -2.91661229e-02  5.77487908e-02\n",
      "   2.41821650e-02 -1.16902897e-02 -6.21435270e-02  2.84351856e-02\n",
      "  -2.37505737e-04 -2.51783393e-02  4.39639995e-03  8.12840015e-02\n",
      "   3.64184305e-02 -6.04006350e-02 -3.65517177e-02 -7.93748572e-02\n",
      "  -5.08524897e-03  6.69698715e-02 -1.17784344e-01  3.23743261e-02\n",
      "  -4.71252948e-02 -1.34459306e-02 -9.48444828e-02  8.24953895e-03\n",
      "  -1.06748985e-02 -6.81881681e-02  1.11812085e-03  2.48020533e-02\n",
      "  -6.35889322e-02  2.84493379e-02 -2.61303913e-02  8.58110636e-02\n",
      "   1.14682272e-01 -5.35345338e-02 -5.63588776e-02  4.26009260e-02\n",
      "   1.09454561e-02  2.09579375e-02  1.00131139e-01  3.26050855e-02\n",
      "  -1.84208781e-01 -3.93208861e-02 -6.91455081e-02 -6.38104975e-02\n",
      "  -6.56386092e-02 -6.41253637e-03 -4.79612574e-02 -7.68133327e-02\n",
      "   2.95384340e-02 -2.29948070e-02  4.17037308e-02 -2.50047557e-02\n",
      "  -4.54508979e-03 -4.17136848e-02 -1.32289873e-02 -6.38356954e-02\n",
      "  -2.46472470e-03 -1.37337688e-02  1.68976691e-02 -6.30398095e-02\n",
      "   8.98880959e-02  4.18171026e-02 -1.85687356e-02 -1.80442168e-08\n",
      "  -1.67997964e-02 -3.21577974e-02  6.30383864e-02 -4.13092151e-02\n",
      "   4.44818623e-02  2.02460168e-03  6.29592612e-02 -5.17371297e-03\n",
      "  -1.00444332e-02 -3.05639710e-02  3.52672711e-02  5.58581911e-02\n",
      "  -4.67124730e-02  3.45102809e-02  3.29577774e-02  4.30114530e-02\n",
      "   2.94360761e-02 -3.03165447e-02 -1.71108022e-02  7.37484768e-02\n",
      "  -5.47910258e-02  2.77515072e-02  6.20166166e-03  1.58800408e-02\n",
      "   3.42978835e-02 -5.15751122e-03  2.35079750e-02  7.53135383e-02\n",
      "   1.92843359e-02  3.36196497e-02  5.09103835e-02  1.52497053e-01\n",
      "   1.64207891e-02  2.70528439e-02  3.75162140e-02  2.18553208e-02\n",
      "   5.66333905e-02 -3.95746231e-02  7.12313056e-02 -5.41376956e-02\n",
      "   1.03762816e-03  2.11852789e-02 -3.56309600e-02  1.09016925e-01\n",
      "   2.76534026e-03  3.13997306e-02  1.38418772e-03 -3.45739126e-02\n",
      "  -4.59277965e-02  2.88082715e-02  7.16904178e-03  4.84684519e-02\n",
      "   2.61018183e-02 -9.44073871e-03  2.82169450e-02  3.48724015e-02\n",
      "   3.69098820e-02 -8.58951826e-03 -3.53205204e-02 -2.47857217e-02\n",
      "  -1.91920958e-02  3.80707718e-02  5.99653646e-02 -4.22287472e-02]\n",
      " [ 8.64385888e-02  1.02762640e-01  5.39458916e-03  2.04440742e-03\n",
      "  -9.96333454e-03  2.53855400e-02  4.92875464e-02 -3.06265540e-02\n",
      "   6.87254816e-02  1.01365959e-02  7.75398090e-02 -9.00807381e-02\n",
      "   6.10620528e-03 -5.69898821e-02  1.41714569e-02  2.80491710e-02\n",
      "  -8.68464783e-02  7.64399171e-02 -1.03491336e-01 -6.77437857e-02\n",
      "   6.99946731e-02  8.44251290e-02 -7.24912714e-03  1.04770586e-02\n",
      "   1.34020457e-02  6.77577108e-02 -9.42086279e-02 -3.71690169e-02\n",
      "   5.22617586e-02 -3.10853366e-02 -9.63407084e-02  1.57716908e-02\n",
      "   2.57866979e-02  7.85245001e-02  7.89949298e-02  1.91516243e-02\n",
      "   1.64356399e-02  3.10086017e-03  3.81311625e-02  2.37091295e-02\n",
      "   1.05389701e-02 -4.40644994e-02  4.41738702e-02 -2.58728303e-02\n",
      "   6.15378916e-02 -4.05427702e-02 -8.64139870e-02  3.19722481e-02\n",
      "  -8.90670461e-04 -2.44437438e-02 -9.19720978e-02  2.33939774e-02\n",
      "  -8.30293149e-02  4.41510603e-02 -2.49692835e-02  6.23019971e-02\n",
      "  -1.30356068e-03  7.51395226e-02  2.46384945e-02 -6.47244602e-02\n",
      "  -1.17727727e-01  3.83392088e-02 -9.11767483e-02  6.35446012e-02\n",
      "   7.62740001e-02 -8.80241320e-02  9.54559539e-03 -4.69717942e-02\n",
      "  -8.41740519e-02  3.88823897e-02 -1.14393570e-01  6.28858898e-03\n",
      "  -3.49361561e-02  2.39750333e-02 -3.31316851e-02 -1.57243591e-02\n",
      "  -3.78955677e-02 -8.81250016e-03  7.06119239e-02  3.28066424e-02\n",
      "   2.03671725e-03 -1.12278976e-01  6.79721730e-03  1.22765750e-02\n",
      "   3.35303508e-02 -1.36201056e-02 -2.25490257e-02 -2.25228723e-02\n",
      "  -2.03194767e-02  5.04297689e-02 -7.48653188e-02 -8.22822154e-02\n",
      "   7.65962452e-02  4.93392088e-02 -3.75553630e-02  1.44634387e-02\n",
      "  -5.72457984e-02 -1.79954451e-02  1.09697938e-01  1.19462796e-01\n",
      "   8.09232588e-04  6.17057420e-02  3.26322243e-02 -1.30780116e-01\n",
      "  -1.48636639e-01 -6.16232567e-02  4.33886126e-02  2.67128982e-02\n",
      "   1.39786378e-02 -3.94002236e-02 -2.52711959e-02  3.87739972e-03\n",
      "   3.58664691e-02 -6.15420304e-02  3.76660600e-02  2.67565288e-02\n",
      "  -3.82659324e-02 -3.54793146e-02 -2.39227302e-02  8.67977366e-02\n",
      "  -1.84062906e-02  7.71039352e-02  1.39863964e-03  7.00383186e-02\n",
      "  -4.77877669e-02 -7.89819732e-02  5.10814749e-02 -2.99868333e-33\n",
      "  -3.91646475e-02 -2.56212428e-03  1.65210851e-02  9.48938169e-03\n",
      "  -5.66219166e-02  6.57783225e-02 -4.77002822e-02  1.11661814e-02\n",
      "  -5.73558398e-02 -9.16259363e-03 -2.17521209e-02 -5.59531376e-02\n",
      "  -1.11422949e-02  9.32793170e-02  1.66765153e-02 -1.36723472e-02\n",
      "   4.34388593e-02  1.87242613e-03  7.29946233e-03  5.16331792e-02\n",
      "   4.80608419e-02  1.35341436e-01 -1.71738882e-02 -1.29698534e-02\n",
      "  -7.50110000e-02  2.61107516e-02  2.69802250e-02  7.83061667e-04\n",
      "  -4.87270355e-02  1.17842704e-02 -4.59580719e-02 -4.83213551e-02\n",
      "  -1.95670873e-02  1.93889495e-02  1.98807362e-02  1.67432260e-02\n",
      "   9.87801030e-02 -2.74087749e-02  2.34808978e-02  3.70227336e-03\n",
      "  -6.14514798e-02 -1.21227256e-03 -9.50472895e-03  9.25154705e-03\n",
      "   2.38443892e-02  8.61231983e-02  2.26789769e-02  5.45135059e-04\n",
      "   3.47129367e-02  6.25465950e-03 -6.92776870e-03  3.92400324e-02\n",
      "   1.15675014e-02  3.26280147e-02  6.22155294e-02  2.76114233e-02\n",
      "   1.86883491e-02  3.55806127e-02  4.11796048e-02  1.54782301e-02\n",
      "   4.22691368e-02  3.82248312e-02  1.00313434e-02 -2.83245929e-02\n",
      "   4.47052345e-02 -4.10458706e-02 -4.50547179e-03 -5.44734038e-02\n",
      "   2.62320731e-02  1.79862585e-02 -1.23118743e-01 -4.66951840e-02\n",
      "  -1.35913454e-02  6.46710545e-02  3.57348891e-03 -1.22233788e-02\n",
      "  -1.79382190e-02 -2.55502202e-02  2.37224195e-02  4.08665929e-03\n",
      "  -6.51476309e-02  4.43651564e-02  4.68596108e-02 -3.25174965e-02\n",
      "   4.02269000e-03 -3.97604285e-03  1.11939693e-02 -9.95597839e-02\n",
      "   3.33168805e-02  8.01060796e-02  9.42692235e-02 -6.38294145e-02\n",
      "   3.23151574e-02 -5.13553508e-02 -7.49879936e-03  5.30048770e-34\n",
      "  -4.13195118e-02  9.49646831e-02 -1.06401421e-01  4.96590622e-02\n",
      "  -3.41913141e-02 -3.16745900e-02 -1.71556175e-02  1.70104660e-03\n",
      "   5.79757988e-02 -1.21775677e-03 -1.68536324e-02 -5.16912714e-02\n",
      "   5.52998856e-02 -3.42647880e-02  3.08179539e-02 -3.10480800e-02\n",
      "   9.27532688e-02  3.72663699e-02 -2.37398222e-02  4.45893779e-02\n",
      "   1.46153420e-02  1.16239361e-01 -5.00112772e-02  3.88716571e-02\n",
      "   4.24742932e-03  2.56976616e-02  3.27244066e-02  4.29907627e-02\n",
      "  -1.36144459e-02  2.56122053e-02  1.06262220e-02 -8.46863985e-02\n",
      "  -9.52982306e-02  1.08399890e-01 -7.51600116e-02 -1.37773519e-02\n",
      "   6.37338385e-02 -4.49671689e-03 -3.25321630e-02  6.23613819e-02\n",
      "   3.48053277e-02 -3.54922526e-02 -2.00222731e-02  3.66608463e-02\n",
      "  -2.48837136e-02  1.01818601e-02 -7.01233223e-02 -4.31951098e-02\n",
      "   2.95332856e-02 -2.94888450e-04 -3.45386937e-02  1.46676013e-02\n",
      "  -9.83970091e-02 -4.70487997e-02 -8.85497779e-03 -8.89914036e-02\n",
      "   3.50995995e-02 -1.29601985e-01 -4.98866476e-02 -6.12047464e-02\n",
      "  -5.97797930e-02  9.46317613e-03  4.91217934e-02 -7.75026530e-02\n",
      "   8.09727088e-02 -4.79257293e-02  2.34378944e-03  7.57031441e-02\n",
      "  -2.40175705e-02 -1.52546056e-02  4.86738607e-02 -3.85968275e-02\n",
      "  -7.04831779e-02 -1.20348269e-02 -3.88790779e-02 -7.76017085e-02\n",
      "  -1.07243741e-02  1.04188453e-02 -2.13754009e-02 -9.17386413e-02\n",
      "  -1.11344885e-02 -2.96066105e-02  2.46458482e-02  4.65710741e-03\n",
      "  -1.63449850e-02 -3.95219773e-02  7.73373917e-02 -2.84732953e-02\n",
      "  -3.69939115e-03  8.27665329e-02 -1.10409185e-02  3.13983150e-02\n",
      "   5.35094514e-02  5.75145818e-02 -3.17622200e-02 -1.52911266e-08\n",
      "  -7.99661502e-02 -4.76797000e-02 -8.59789103e-02  5.69616817e-02\n",
      "  -4.08866592e-02  2.23832428e-02 -4.64449264e-03 -3.80130298e-02\n",
      "  -3.10671069e-02 -1.07277669e-02  1.97698679e-02  7.77001074e-03\n",
      "  -6.09472487e-03 -3.86376269e-02  2.80271936e-02  6.78137764e-02\n",
      "  -2.35351678e-02  3.21747474e-02  8.02537147e-03 -2.39107218e-02\n",
      "  -1.21994631e-03  3.14599015e-02 -5.24924137e-02 -8.06815922e-03\n",
      "   3.14775133e-03  5.11496328e-02 -4.44104373e-02  6.36013523e-02\n",
      "   3.85083891e-02  3.30432802e-02 -4.18728031e-03  4.95592505e-02\n",
      "  -5.69605231e-02 -6.49713771e-03 -2.49792933e-02 -1.60867199e-02\n",
      "   6.62289336e-02 -2.06310786e-02  1.08045742e-01  1.68547276e-02\n",
      "   1.43812243e-02 -1.32127414e-02 -1.29387379e-01  6.95216358e-02\n",
      "  -5.55773005e-02 -6.75413311e-02 -5.45819802e-03 -6.13593729e-03\n",
      "   3.90840992e-02 -6.28779680e-02  3.74063365e-02 -1.16570676e-02\n",
      "   1.29150124e-02 -5.52495308e-02  5.16075976e-02 -4.30841977e-03\n",
      "   5.80247864e-02  1.86945014e-02  2.27810405e-02  3.21665592e-02\n",
      "   5.37978858e-02  7.02849105e-02  7.49312118e-02 -8.41775015e-02]]\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers usearch numpy pandas\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import usearch.index\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "DIMENSION = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ecf5e-cc7e-4620-8c81-9668c4192cee",
   "metadata": {},
   "source": [
    "## Part 1: Prototype Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37383499-7a03-42f9-8a1f-c53ad69964d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: (4, 384)\n",
      "Embedding dimension (D): 384\n",
      "Index created with 4 vectors.\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"def calculate_factorial(n): # Computes the product of all positive integers less than or equal to n.\",\n",
    "    \"class DatabaseConnector: # Manages the connection pool to a SQL database.\",\n",
    "    \"def quicksort(arr): # Sorts an array using the divide and conquer method.\",\n",
    "    \"def binary_search(arr, target): # Finds the position of a target value within a sorted array.\",\n",
    "]\n",
    "doc_ids = np.array([1, 2, 3, 4], dtype=np.longlong)\n",
    "\n",
    "document_embeddings = model.encode(documents, convert_to_numpy=True)\n",
    "print(f\"Generated embeddings shape: {document_embeddings.shape}\")\n",
    "print(f\"Embedding dimension (D): {DIMENSION}\")\n",
    "\n",
    "index = usearch.index.Index(\n",
    "    ndim=DIMENSION,\n",
    "    metric='cos',\n",
    ")\n",
    "index.add(doc_ids, document_embeddings)\n",
    "print(f\"Index created with {index.size} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09f2011-20c4-4221-ad74-4531a1528ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Search Results for Query: 'Find a function to sort elements quickly.' ---\n",
      "Rank 1 (Score: 0.5863, ID: 3):\n",
      "    Code: def quicksort(arr): # Sorts an array using the divide and conquer method.\n",
      "Rank 2 (Score: 0.3575, ID: 4):\n",
      "    Code: def binary_search(arr, target): # Finds the position of a target value within a sorted array.\n",
      "Rank 3 (Score: 0.1400, ID: 1):\n",
      "    Code: def calculate_factorial(n): # Computes the product of all positive integers less than or equal to n.\n"
     ]
    }
   ],
   "source": [
    "def search_code(query, k=3):\n",
    "    \"\"\"Encodes a query and searches the index for the top k similar documents.\"\"\"\n",
    "    \n",
    "    query_embedding = model.encode(query, convert_to_numpy=True).reshape(1, -1)\n",
    "    matches = index.search(query_embedding, k)\n",
    "\n",
    "    id_to_doc = {id: doc for id, doc in zip(doc_ids, documents)}\n",
    "    \n",
    "    results = []\n",
    "    for rank, (doc_id, distance) in enumerate(zip(matches.keys, matches.distances)):\n",
    "        similarity = 1 - distance\n",
    "        results.append({\n",
    "            \"rank\": rank + 1,\n",
    "            \"document_id\": doc_id,\n",
    "            \"document\": id_to_doc.get(doc_id, \"Document Not Found\"),\n",
    "            \"similarity_score\": similarity\n",
    "        })\n",
    "    return results\n",
    "\n",
    "test_query = \"Find a function to sort elements quickly.\"\n",
    "search_results = search_code(test_query)\n",
    "print(f\"--- Search Results for Query: '{test_query}' ---\")\n",
    "for result in search_results:\n",
    "    print(f\"Rank {result['rank']} (Score: {result['similarity_score']:.4f}, ID: {result['document_id']}):\")\n",
    "    print(f\"    Code: {result['document']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48cd13-dcdb-4da0-8094-9ecb8358f364",
   "metadata": {},
   "source": [
    "## Part 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f2bfb9-8fd9-478a-8631-a24cf6687eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from: https://raw.githubusercontent.com/microsoft/CodeXGLUE/main/Text-Code/NL-code-search-WebQuery/data/test_webquery.json\n",
      "Data successfully downloaded and saved to cosqa_test_data.json\n",
      "\n",
      "Successfully loaded CoSQA data:\n",
      "- Total code snippets (Documents) to index: 1046\n",
      "- Total queries for evaluation: 1046\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "import os\n",
    "\n",
    "RAW_FILE_URL = \"https://raw.githubusercontent.com/microsoft/CodeXGLUE/main/Text-Code/NL-code-search-WebQuery/data/test_webquery.json\"\n",
    "LOCAL_FILE_PATH = \"cosqa_test_data.json\"\n",
    "\n",
    "def fetch_and_process_cosqa(url, local_path):\n",
    "    \"\"\"Fetches the CoSQA test file, saves it locally, and processes it into a searchable format.\"\"\"\n",
    "    \n",
    "    print(f\"Fetching data from: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(local_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Data successfully downloaded and saved to {local_path}\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data. Check your connection: {e}\")\n",
    "        return [], [], {}, {}\n",
    "    \n",
    "    try:\n",
    "        with open(local_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "            data_list = raw_data \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read or parse local JSON file: {e}\")\n",
    "        return [], [], {}, {}\n",
    "\n",
    "    if not data_list:\n",
    "        print(\"Data list for iteration is empty.\")\n",
    "        return [], [], {}, {}\n",
    "    \n",
    "    corpus = {} \n",
    "    queries = {}\n",
    "    qrels = {}\n",
    "\n",
    "    for item in data_list: \n",
    "        q_id = item.get('idx')\n",
    "        q_text = item.get('doc')\n",
    "        code_text = item.get('code')\n",
    "        c_id = q_id \n",
    "        \n",
    "        if not q_id or not q_text or not code_text:\n",
    "            continue\n",
    "\n",
    "        queries[q_id] = q_text\n",
    "        corpus[c_id] = code_text\n",
    "        qrels[q_id] = c_id\n",
    "\n",
    "    corpus_items = list(corpus.items())\n",
    "    new_corpus_ids = np.arange(1, len(corpus_items) + 1, dtype=np.longlong)\n",
    "    old_to_new_id_map = {old_id: new_id for new_id, (old_id, _) in zip(new_corpus_ids, corpus_items)}\n",
    "    \n",
    "    COSQA_DOCUMENTS = [code for _, code in corpus_items]\n",
    "    COSQA_DOC_IDS = new_corpus_ids\n",
    "    \n",
    "    COSQA_QRELS = {}\n",
    "    for q_id, old_c_id in qrels.items():\n",
    "        correct_new_id = old_to_new_id_map.get(old_c_id)\n",
    "        if correct_new_id:\n",
    "            COSQA_QRELS[q_id] = correct_new_id\n",
    "            \n",
    "    COSQA_QUERIES = queries\n",
    "\n",
    "    print(f\"\\nSuccessfully loaded CoSQA data:\")\n",
    "    print(f\"- Total code snippets (Documents) to index: {len(COSQA_DOCUMENTS)}\")\n",
    "    print(f\"- Total queries for evaluation: {len(COSQA_QUERIES)}\")\n",
    "\n",
    "    return COSQA_DOCUMENTS, COSQA_DOC_IDS, COSQA_QUERIES, COSQA_QRELS\n",
    "\n",
    "COSQA_DOCUMENTS, COSQA_DOC_IDS, COSQA_QUERIES, COSQA_QRELS = fetch_and_process_cosqa(RAW_FILE_URL, LOCAL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f6346b-e9db-43a2-b375-ca5867f60ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing the CoSQA Corpus...\n",
      "Generated embeddings for CoSQA corpus. Shape: (1046, 384)\n",
      "CoSQA Index created successfully with 1046 code snippets.\n"
     ]
    }
   ],
   "source": [
    "print(\"Indexing the CoSQA Corpus...\")\n",
    "\n",
    "if len(COSQA_DOCUMENTS) > 0:\n",
    "    COSQA_DOCUMENT_EMBEDDINGS = model.encode(\n",
    "        COSQA_DOCUMENTS, \n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    print(f\"Generated embeddings for CoSQA corpus. Shape: {COSQA_DOCUMENT_EMBEDDINGS.shape}\")\n",
    "\n",
    "    cosqa_index = usearch.index.Index(\n",
    "        ndim=DIMENSION,\n",
    "        metric='cos', \n",
    "    )\n",
    "    cosqa_index.add(COSQA_DOC_IDS, COSQA_DOCUMENT_EMBEDDINGS)\n",
    "    print(f\"CoSQA Index created successfully with {cosqa_index.size} code snippets.\")\n",
    "else:\n",
    "    print(\"No documents were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b0bc21-4f18-4d1d-8390-a9393c77941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 1046 queries at k=10...\n",
      "\n",
      "--- BASELINE (all-MiniLM-L6-v2) METRICS ---\n",
      "{\n",
      "    \"Recall@10\": 0.5898661567877629,\n",
      "    \"MRR@10\": 0.295947145588637,\n",
      "    \"NDCG@10\": 0.3654286274711419\n",
      "}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr(relevance_list, k):\n",
    "    \"\"\"Calculates Mean Reciprocal Rank (MRR) for a single query.\"\"\"\n",
    "    for rank, is_relevant in enumerate(relevance_list):\n",
    "        if is_relevant == 1.0:\n",
    "            return 1.0 / (rank + 1)\n",
    "    return 0.0\n",
    "\n",
    "def calculate_ndcg(relevance_list, k):\n",
    "    \"\"\"Calculates Normalized Discounted Cumulative Gain (NDCG) for a single query.\"\"\"\n",
    "\n",
    "    idcg = 1.0 \n",
    "\n",
    "    dcg = 0.0\n",
    "    for rank, rel in enumerate(relevance_list):\n",
    "        if rel == 1.0:\n",
    "            dcg += rel / np.log2(rank + 2)\n",
    "            break\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate_search_engine(index, queries, qrels, model, k=10):\n",
    "    \"\"\"\n",
    "    Evaluates the search engine using Recall@k, MRR@k, and NDCG@k against the entire test set.\n",
    "    \"\"\"\n",
    "    print(f\"Starting evaluation of {len(queries)} queries at k={k}...\")\n",
    "    \n",
    "    recall_k_list = []\n",
    "    mrr_k_list = []\n",
    "    ndcg_k_list = []\n",
    "\n",
    "    for q_id, query_text in queries.items():\n",
    "        query_embedding = model.encode(query_text, convert_to_numpy=True).reshape(1, -1)\n",
    "        matches = index.search(query_embedding, k)\n",
    "        retrieved_ids = matches.keys.tolist()\n",
    "        correct_id = qrels.get(q_id)\n",
    "        \n",
    "        if correct_id is None:\n",
    "            continue\n",
    "\n",
    "        is_relevant = [1.0 if doc_id == correct_id else 0.0 for doc_id in retrieved_ids]\n",
    "        \n",
    "        recall_k_list.append(1.0 if correct_id in retrieved_ids else 0.0)\n",
    "        mrr_k_list.append(calculate_mrr(is_relevant, k))\n",
    "        ndcg_k_list.append(calculate_ndcg(is_relevant, k))\n",
    "\n",
    "    results = {\n",
    "        f\"Recall@{k}\": np.mean(recall_k_list) if recall_k_list else 0.0,\n",
    "        f\"MRR@{k}\": np.mean(mrr_k_list) if mrr_k_list else 0.0,\n",
    "        f\"NDCG@{k}\": np.mean(ndcg_k_list) if ndcg_k_list else 0.0,\n",
    "    }\n",
    "    return results\n",
    "\n",
    "if 'cosqa_index' in locals():\n",
    "    BASELINE_METRICS = evaluate_search_engine(\n",
    "        index=cosqa_index, \n",
    "        queries=COSQA_QUERIES, \n",
    "        qrels=COSQA_QRELS, \n",
    "        model=model, \n",
    "        k=10\n",
    "    )\n",
    "    print(\"\\n--- BASELINE (all-MiniLM-L6-v2) METRICS ---\")\n",
    "    print(json.dumps(BASELINE_METRICS, indent=4))\n",
    "    print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"\\nERROR: cosqa_index was not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d0b31-f12b-49e9-a4c6-f524f69ec769",
   "metadata": {},
   "source": [
    "## Part 3: Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8b7469-a19e-4c9e-8ed1-aee9dfa4b1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Step 7: Fetching training data from: https://raw.githubusercontent.com/Jun-jie-Huang/CoCLR/main/data/search/cosqa-retrieval-train-19604.json\n",
      "Training data successfully downloaded and saved to cosqa_train_data.json\n",
      "Total training pairs loaded: 19604\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE_URL = \"https://raw.githubusercontent.com/Jun-jie-Huang/CoCLR/main/data/search/cosqa-retrieval-train-19604.json\"\n",
    "LOCAL_TRAIN_PATH = \"cosqa_train_data.json\" \n",
    "\n",
    "def fetch_cosqa_training_data(url, local_path):\n",
    "    print(f\"Starting Step 7: Fetching training data from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        with open(local_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Training data successfully downloaded and saved to {local_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with open(local_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "            return raw_data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read or parse local JSON file: {e}\")\n",
    "        return []\n",
    "\n",
    "COSQA_TRAIN_DATA = fetch_cosqa_training_data(TRAIN_FILE_URL, LOCAL_TRAIN_PATH)\n",
    "\n",
    "print(f\"Total training pairs loaded: {len(COSQA_TRAIN_DATA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72ae6a0-dfa1-4907-ac00-ba8759205c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6104272a-cfb6-4e43-8d2a-6c201cc20183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 19604 training examples.\n",
      "Starting fine-tuning for 1 epoch(s) on 19604 examples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ebbb002f7d4c91a3e27092d63b83e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aycay\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='613' max='613' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [613/613 27:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning complete!\n",
      "Model saved to: output/finetuned_cosqa_20251111_133933\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "if len(COSQA_TRAIN_DATA) == 0:\n",
    "    print(\"Training data is empty, cannot fine-tune.\")\n",
    "else:\n",
    "    train_examples = []\n",
    "    for item in COSQA_TRAIN_DATA:\n",
    "        query = item.get('doc')\n",
    "        code = item.get('code') \n",
    "        \n",
    "        if query and code:\n",
    "            train_examples.append(InputExample(texts=[query, code]))\n",
    "\n",
    "    print(f\"Created {len(train_examples)} training examples.\")\n",
    "    \n",
    "    if len(train_examples) == 0:\n",
    "        print(\"Zero training examples were created.\")\n",
    "    else:\n",
    "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "        train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "        \n",
    "        num_epochs = 1\n",
    "        warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "        \n",
    "        model_save_path = f'output/finetuned_cosqa_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Starting fine-tuning for {num_epochs} epoch(s) on {len(train_examples)} examples...\")\n",
    "\n",
    "        model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=num_epochs,\n",
    "            warmup_steps=warmup_steps,\n",
    "            output_path=model_save_path,\n",
    "            save_best_model=True,\n",
    "        )\n",
    "\n",
    "        print(\"\\nFine-tuning complete!\")\n",
    "        print(f\"Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c558afa2-faab-40df-b137-0045de298240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-indexing Corpus with Fine-Tuned Model...\n",
      "Generated embeddings with fine-tuned model. Shape: (1046, 384)\n",
      "Fine-Tuned Index created successfully with 1046 code snippets.\n",
      "Starting evaluation of 1046 queries at k=10...\n",
      "\n",
      "--- FINAL RESULTS COMPARISON (Part 3 Complete) ---\n",
      "Baseline (all-MiniLM-L6-v2):\n",
      "{\n",
      "    \"Recall@10\": 0.5898661567877629,\n",
      "    \"MRR@10\": 0.295947145588637,\n",
      "    \"NDCG@10\": 0.3654286274711419\n",
      "}\n",
      "\n",
      "Fine-Tuned Model:\n",
      "{\n",
      "    \"Recall@10\": 0.6577437858508605,\n",
      "    \"MRR@10\": 0.33761229475856624,\n",
      "    \"NDCG@10\": 0.4140278985967439\n",
      "}\n",
      "\n",
      "--- Improvement Summary ---\n",
      "Recall@10 Improvement: 0.0679\n",
      "MRR@10 Improvement: 0.0417\n",
      "NDCG@10 Improvement: 0.0486\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRe-indexing Corpus with Fine-Tuned Model...\")\n",
    "\n",
    "FINE_TUNED_EMBEDDINGS = model.encode(\n",
    "    COSQA_DOCUMENTS, \n",
    "    convert_to_numpy=True, \n",
    "    show_progress_bar=False\n",
    ")\n",
    "print(f\"Generated embeddings with fine-tuned model. Shape: {FINE_TUNED_EMBEDDINGS.shape}\")\n",
    "\n",
    "FINETUNED_INDEX = usearch.index.Index(\n",
    "    ndim=DIMENSION,\n",
    "    metric='cos', \n",
    ")\n",
    "FINETUNED_INDEX.add(COSQA_DOC_IDS, FINE_TUNED_EMBEDDINGS)\n",
    "print(f\"Fine-Tuned Index created successfully with {FINETUNED_INDEX.size} code snippets.\")\n",
    "\n",
    "FINE_TUNED_METRICS = evaluate_search_engine(\n",
    "    index=FINETUNED_INDEX, \n",
    "    queries=COSQA_QUERIES, \n",
    "    qrels=COSQA_QRELS, \n",
    "    model=model, \n",
    "    k=10\n",
    ")\n",
    "\n",
    "print(\"\\n--- FINAL RESULTS COMPARISON (Part 3 Complete) ---\")\n",
    "\n",
    "print(\"Baseline (all-MiniLM-L6-v2):\")\n",
    "print(json.dumps(BASELINE_METRICS, indent=4))\n",
    "\n",
    "print(\"\\nFine-Tuned Model:\")\n",
    "print(json.dumps(FINE_TUNED_METRICS, indent=4))\n",
    "\n",
    "print(\"\\n--- Improvement Summary ---\")\n",
    "print(f\"Recall@10 Improvement: {FINE_TUNED_METRICS['Recall@10'] - BASELINE_METRICS['Recall@10']:.4f}\")\n",
    "print(f\"MRR@10 Improvement: {FINE_TUNED_METRICS['MRR@10'] - BASELINE_METRICS['MRR@10']:.4f}\")\n",
    "print(f\"NDCG@10 Improvement: {FINE_TUNED_METRICS['NDCG@10'] - BASELINE_METRICS['NDCG@10']:.4f}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d8764-1760-40a1-8692-9464b4bf450e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
